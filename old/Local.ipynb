{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6eba7acc-e798-43d4-8f0e-fbfe07db9956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Downloading: \"https://github.com/snakers4/silero-vad/zipball/master\" to /home/bchen/.cache/torch/hub/master.zip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording started...\n",
      "Falling back to processing after finish.\n",
      "Recording stopped\n",
      " The AC circuit owner in figure 3 is connected to a 240 volts 50hertz power supply, determine the total complex impedance of the circuit and hence find the magnitude and faith with it back to the voltage source of the input current.\n"
     ]
    }
   ],
   "source": [
    "import pyaudio\n",
    "import wave\n",
    "import threading\n",
    "import torch\n",
    "import ctypes\n",
    "from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline\n",
    "\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\n",
    "torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32\n",
    "\n",
    "model_id = \"distil-whisper/distil-medium.en\"\n",
    "\n",
    "model_whisper = AutoModelForSpeechSeq2Seq.from_pretrained(\n",
    "    model_id, torch_dtype=torch_dtype, low_cpu_mem_usage=True, use_safetensors=True\n",
    ")\n",
    "model_whisper.to(device)\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(model_id)\n",
    "\n",
    "pipe = pipeline(\n",
    "    \"automatic-speech-recognition\",\n",
    "    model=model_whisper,\n",
    "    tokenizer=processor.tokenizer,\n",
    "    feature_extractor=processor.feature_extractor,\n",
    "    max_new_tokens=128,\n",
    "    torch_dtype=torch_dtype,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "model, utils = torch.hub.load(repo_or_dir='snakers4/silero-vad',\n",
    "                              model='silero_vad',\n",
    "                              force_reload=True,\n",
    "                              onnx=False)\n",
    "(get_speech_timestamps,\n",
    " save_audio,\n",
    " read_audio,\n",
    " VADIterator,\n",
    " collect_chunks) = utils\n",
    "vad_iterator = VADIterator(model)\n",
    "\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 16000\n",
    "CHUNK = 1536\n",
    "\n",
    "frames5 = []\n",
    "frames10 = []\n",
    "all_frames = []\n",
    "all_speech_probs = []\n",
    "recording = False\n",
    "BOUNDARY = 0.2\n",
    "\n",
    "final_result = \"\"\n",
    "calc_result_running = False\n",
    "fallback = False\n",
    "\n",
    "\n",
    "def calc_result(counts):\n",
    "    global calc_result_running, final_result\n",
    "\n",
    "    calc_result_running = True\n",
    "\n",
    "    filename = \"test_\" + str(counts) + \".wav\"\n",
    "    result = pipe(filename)\n",
    "\n",
    "    final_result = result[\"text\"]\n",
    "\n",
    "    calc_result_running = False    \n",
    "           \n",
    "def audio_recording():\n",
    "    global frames5, frames10, all_frames, all_speech_probs, fallback\n",
    "\n",
    "    # Open the audio file\n",
    "    file_path = \"recording_test.wav\"\n",
    "    audio_file = wave.open(file_path, 'rb')\n",
    "    #audio = pyaudio.PyAudio()\n",
    "    #stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "    #                    rate=RATE, input=True,\n",
    "    #                    frames_per_buffer=CHUNK)\n",
    "    print(\"Recording started...\")\n",
    "    tot_len = 0\n",
    "    data = audio_file.readframes(CHUNK)\n",
    "    while data and recording:\n",
    "        #data = audio_file.readframes(CHUNK)\n",
    "        all_frames.append(data)\n",
    "        frames10.append(data)\n",
    "\n",
    "        tot_len += 1\n",
    "        if tot_len >= 6:\n",
    "            frames5.append(data)\n",
    "            \n",
    "        if tot_len % 10 == 0 and not fallback:\n",
    "            filename = \"test_\" + str(tot_len) + \".wav\"\n",
    "            wf = wave.open(filename, 'wb')\n",
    "            wf.setnchannels(CHANNELS)\n",
    "            wf.setsampwidth(pyaudio.PyAudio().get_sample_size(FORMAT))\n",
    "            wf.setframerate(RATE)\n",
    "            wf.writeframes(b''.join(all_frames))\n",
    "            if calc_result_running and my_thread:\n",
    "                if my_thread.is_alive():\n",
    "                    fallback = True\n",
    "                    print(\"Falling back to processing after finish.\")\n",
    "                # print(\"Killing thread: \" + str(my_thread.ident))\n",
    "                # ctypes.pythonapi.PyThreadState_SetAsyncExc(ctypes.c_long(my_thread.ident), ctypes.py_object(SystemExit))\n",
    "            if not fallback:\n",
    "                my_thread = threading.Thread(\n",
    "                    target=calc_result, args=(tot_len,))\n",
    "                # print(\"Running new thread\")\n",
    "                my_thread.start()\n",
    "            \n",
    "        if len(frames5) == 10:\n",
    "            frames5_data = b''.join(frames5)\n",
    "            numbers = [int.from_bytes(frames5_data[i:i+2], byteorder='little', signed=False) for i in range(0, len(frames5_data), 2)]\n",
    "            max_val = max(numbers)\n",
    "            min_val = min(numbers)\n",
    "            normalized_numbers = [(num - min_val) * 2 / (max_val - min_val) for num in numbers]\n",
    "            wav = torch.tensor(normalized_numbers, dtype=torch.float32)\n",
    "            window_size_samples = 1536\n",
    "            speech_probs = []\n",
    "            for i in range(0, len(wav), window_size_samples):\n",
    "                chunk = wav[i: i+ window_size_samples]\n",
    "                if len(chunk) < window_size_samples:\n",
    "                    break\n",
    "                speech_prob = model(chunk, 16000).item()\n",
    "                speech_probs.append(speech_prob)\n",
    "            vad_iterator.reset_states()\n",
    "            all_speech_probs += speech_probs[:10]\n",
    "            \n",
    "            if max(speech_probs[:10]) <= BOUNDARY:           \n",
    "                stop_recording()\n",
    "            \n",
    "            frames5 = []\n",
    " \n",
    "        if len(frames10) == 10:\n",
    "            frames10_data = b''.join(frames10)\n",
    "            numbers = [int.from_bytes(frames10_data[i:i+2], byteorder='little', signed=False) for i in range(0, len(frames10_data), 2)]\n",
    "            max_val = max(numbers)\n",
    "            min_val = min(numbers)\n",
    "            normalized_numbers = [(num - min_val) * 2 / (max_val - min_val) for num in numbers]\n",
    "            wav = torch.tensor(normalized_numbers, dtype=torch.float32)\n",
    "            window_size_samples = 1536\n",
    "            speech_probs = []\n",
    "            for i in range(0, len(wav), window_size_samples):\n",
    "                chunk = wav[i: i+ window_size_samples]\n",
    "                if len(chunk) < window_size_samples:\n",
    "                    break\n",
    "                speech_prob = model(chunk, 16000).item()\n",
    "                speech_probs.append(speech_prob)\n",
    "            vad_iterator.reset_states()\n",
    "            all_speech_probs += speech_probs[:10]\n",
    "            \n",
    "            if max(speech_probs[:10]) <= BOUNDARY:         \n",
    "                stop_recording()\n",
    "            \n",
    "            frames10 = []\n",
    "            \n",
    "        data = audio_file.readframes(CHUNK)\n",
    "        \n",
    "            \n",
    "def start_recording():\n",
    "    global frames5, frames10, all_frames, recording\n",
    "    frames5 = []  # Clear existing frames\n",
    "    frames10 = []\n",
    "    all_frames = []\n",
    "    recording = True\n",
    "    main_thread = threading.Thread(target=audio_recording)\n",
    "    main_thread.start()\n",
    "    main_thread.join()\n",
    "\n",
    "def stop_recording():\n",
    "    global recording\n",
    "    recording = False\n",
    "    print(\"Recording stopped\")\n",
    "\n",
    "    if not fallback:\n",
    "        while calc_result_running:\n",
    "            continue\n",
    "        print(final_result)\n",
    "\n",
    "    else:\n",
    "        filename = 'recording_all.wav'\n",
    "        wf = wave.open(filename, 'wb')\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(pyaudio.PyAudio().get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "        wf.writeframes(b''.join(all_frames))\n",
    "        wf.close()\n",
    "        result = pipe(\"recording_all.wav\")\n",
    "        print(result['text'])\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    start_recording()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2473e-49ca-4e8c-8254-dcd759339a7b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
